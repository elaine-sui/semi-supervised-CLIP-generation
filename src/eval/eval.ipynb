{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('/pasteur/u/esui/repos/semi-supervised-CLIP-generation/')\n",
    "\n",
    "from eval_new_gens import run_eval"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/pasteur/u/esui/miniconda3/envs/clip_prefix_caption2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package wordnet to /sailhome/esui/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /sailhome/esui/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /sailhome/esui/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "dir = \"reformatted_from_new_repo\"\n",
    "os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "raw_pred_dir = \"/pasteur/u/esui/repos/c3/cache\"\n",
    "\n",
    "file_names = [\n",
    "    \"generation_clip_c1_0.1_1_best_full.json\",\n",
    "    \"generation_clip_c21_0.1_1_best_full.json\",\n",
    "    \"generation_clip_c22_0.1_7_best_full.json\",\n",
    "    \"generation_clip_c3_0.1_16_best_full.json\",\n",
    "    \"generation_imagebind_c1_0.1_1_best_full.json\",\n",
    "    \"generation_imagebind_c21_0.1_1_best_full.json\",\n",
    "    \"generation_imagebind_c22_0.1_1_best_full.json\",\n",
    "    \"generation_imagebind_c3_0.1_6_best_full.json\"\n",
    "]\n",
    "\n",
    "labels_json = '/pasteur/u/yuhuiz/data/COCO/annotations/captions_val2017.json'\n",
    "\n",
    "for filename in file_names:\n",
    "    raw_pred_file = os.path.join(raw_pred_dir, filename)\n",
    "    out_file = f'{dir}/{filename[:-5]}_metrics.json'\n",
    "\n",
    "    run_eval(raw_pred_file, labels_json, out_file=out_file, dir=dir)\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "New pred file: reformatted_from_new_repo/converted_preds.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "PTBTokenizer tokenized 307315 tokens at 582574.02 tokens per second.\n",
      "PTBTokenizer tokenized 77000 tokens at 269141.96 tokens per second.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 65856, 'reflen': 57166, 'guess': [65856, 60856, 55856, 50856], 'correct': [26081, 6425, 1406, 300]}\n",
      "ratio: 1.1520134345589834\n",
      "Bleu_1: 0.396\n",
      "Bleu_2: 0.204\n",
      "Bleu_3: 0.102\n",
      "Bleu_4: 0.050\n",
      "computing METEOR score...\n",
      "METEOR: 0.142\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.305\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.213\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.9 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [2.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [1.0 sec].\n",
      "Threads( StanfordCoreNLP ) "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.16",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.16 64-bit ('clip_prefix_caption2': conda)"
  },
  "interpreter": {
   "hash": "b9a897870f89d72e3f0e339b8f347f274cca8b2d5960bd08ef4da7a9cc09c88a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}