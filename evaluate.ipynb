{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from src.eval import evaluate_on_coco_caption\n",
    "\n",
    "audio_json = '/pasteur/u/yuhuiz/iccv_c3/cache/generation_data_audio_clotho_imagebind.pkl_c3_0.1_1.json'\n",
    "\n",
    "with open(audio_json, 'rb') as f:\n",
    "    gens, refs = json.load(f)\n",
    "\n",
    "gens, refs = gens[0], refs[0]\n",
    "gens = [gen.replace(\"<|endoftext|>\", \"\").strip() for gen in gens]\n",
    "\n",
    "pred_file = 'audio_pred_coco_format.json'\n",
    "label_file = 'audio_label_coco_format.json'\n",
    "out_file = 'audio_metrics.json'\n",
    "\n",
    "print(len(gens), len(refs))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1045 1045\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def reformat_captions_list_to_coco(captions, out_path, label=False):\n",
    "\n",
    "    labels = {\"annotations\": [], \"images\": []}\n",
    "    \n",
    "    for id, caption in tqdm(enumerate(captions)):\n",
    "        image_dict = {\"id\": id}\n",
    "        labels[\"images\"].append(image_dict)\n",
    "\n",
    "        caption_dict = {\"image_id\": id, \"caption\": caption, \"id\": id}\n",
    "        labels[\"annotations\"].append(caption_dict)\n",
    "        \n",
    "    if not label:\n",
    "        labels = labels['annotations']\n",
    "        print(f\"Total number of predictions: {len(labels)}\")\n",
    "    else:\n",
    "        print(f\"Total number of annotations: {len(labels['annotations'])}\")\n",
    "        print(f\"Total number of audio clips: {len(labels['images'])}\")\n",
    "    with open(out_path, 'w') as f:\n",
    "        json.dump(labels, f)\n",
    "        \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "reformat_captions_list_to_coco(gens, pred_file, label=False)\n",
    "reformat_captions_list_to_coco(refs, label_file, label=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1045it [00:00, 241450.32it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of predictions: 1045\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1045it [00:00, 585030.39it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of annotations: 1045\n",
      "Total number of audio clips: 1045\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "metrics_dict = evaluate_on_coco_caption(pred_file, label_file, out_file)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "PTBTokenizer tokenized 14169 tokens at 77997.45 tokens per second.\n",
      "PTBTokenizer tokenized 16608 tokens at 105098.08 tokens per second.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 14519, 'reflen': 12009, 'guess': [14519, 13474, 12429, 11384], 'correct': [3023, 521, 161, 46]}\n",
      "ratio: 1.2090099092346398\n",
      "Bleu_1: 0.208\n",
      "Bleu_2: 0.090\n",
      "Bleu_3: 0.047\n",
      "Bleu_4: 0.025\n",
      "computing METEOR score...\n",
      "METEOR: 0.087\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.213\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.177\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Threads( StanfordCoreNLP ) [44.949 seconds]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SPICE evaluation took: 52.69 s\n",
      "SPICE: 0.071\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(metrics_dict)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.16",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.16 64-bit ('clip_prefix_caption2': conda)"
  },
  "interpreter": {
   "hash": "b9a897870f89d72e3f0e339b8f347f274cca8b2d5960bd08ef4da7a9cc09c88a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}