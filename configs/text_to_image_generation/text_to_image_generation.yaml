experiment_name: 'coco_stage2_image_generation'

lightning:
  trainer:
    gpus: 1
    #distributed_backend: 'ddp'
    max_epochs: 2
    lr: 2e-5
    precision: 16
    auto_lr_find: false
    limit_val_batches: 2
    limit_train_batches: 2
  checkpoint_callback:
    monitor: 'train_loss_epoch'
    dirpath: '/pasteur/u/esui/data/coco/ckpt'
    # save_last: true
    mode: 'min'
    # save_top_k: 10
  early_stopping_callback:
    monitor: 'train_loss_epoch'
    min_delta: 0.00
    patience: 10
    verbose: False
    mode: 'min'
  logger:
    logger_type: 'WandbLogger'
    save_dir: '/pasteur/u/esui/data/logger/'
    name: 'clip_prefix_cap_coco'
    project: 'clip_prefix_cap_coco'

encoder:
    clip_model_type: 'ViT-B/32'
    modality: 'language' # 'vision' 'language', 'both'
    embed_dim: 512


decoder:
    modality: 'vision' # 'vision' 'language'
    
    # Decode to language (ignored if modality is image)
    model: 'gpt2'
    
    # Decode to image (ignored if modality is language)
    embed_dim: 512
    num_heads: 16
    mlp_ratio: 4.
    depth: 8
    patch_size: 16
    in_chans: 3
    img_size: 224
    checkpoint: '/pasteur/u/esui/data/ckpt/mae_visualize_vit_base.pth'


model: 
  num_layers: 8
  mapping_type: 'mlp'
  prefix_length: 50 # roughly 25% of the patches in 224x224
  clip_size: 10
  normalize_prefix: False
  is_rn: False
  gpt2_type: 'gpt2'

data: 
  dataset: 'coco'
  seed: 1234
  train_split: 'train' # train, restval, train+restval
  train_data_path: '/pasteur/u/esui/data/coco/oscar_split_ViT-B_32_train.pkl'
  val_data_path: '/pasteur/u/esui/data/coco/oscar_split_ViT-B_32_val.pkl'
  test_data_path: '/pasteur/u/esui/data/coco/oscar_split_ViT-B_32_test.pkl'
  out_dir: '/pasteur/u/esui/data/coco/clip_prefix_cap_refactored_ckpts'
    
train: 
  batch_size: 40
  num_workers: 8
  warmup_epochs: 2 # warmup_steps = 5000 (warmup_epochs = 414113 (num_steps_per_epoch) / 5000)
  loss_fn: 
    name: 'image_reconstruction_loss'
  optimizer: 
    name: 'AdamW'

