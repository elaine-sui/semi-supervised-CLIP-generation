experiment_name: 'coco_stage1_llama_v2'

lightning:
  trainer:
    devices: -1
    max_epochs: 20
    lr: 1e-3
    precision: bf16
  checkpoint_callback:
    monitor: 'val/meteor'
    dirpath: '/pasteur/u/esui/data/coco/ckpt'
    save_last: true
    mode: 'max'
    save_top_k: 1
  logger:
    logger_type: 'WandbLogger'
    save_dir: '/pasteur/u/esui/data/logger/'
    name: 'c3'
    project: 'c3'

encoder:
    modality: 'language'
    embed_dim: 1024

decoder:
    # Decode to language
    modality: 'language'
    model: 'meta-llama/Llama-2-7b-hf'

model: 
  mapping_type: 'transformer'
  prefix_length: 10
  clip_size: 10
  num_layers: 2
  # is_rn: False

data: 
  dataset: 'coco'
  seed: 1234
  train_split: 'train'
  train_data_path: '/pasteur/u/esui/data/coco/oscar_split_imagebind_train.pkl'
  val_data_path: '/pasteur/u/esui/data/coco/oscar_split_imagebind_val.pkl'
  test_data_path: '/pasteur/u/esui/data/coco/oscar_split_imagebind_test.pkl'
  text_embed_mean_path: '/pasteur/u/esui/data/coco/imagebind_normalized_text_embed_mean.pkl'
  image_embed_mean_path: '/pasteur/u/esui/data/coco/imagebind_normalized_image_embed_mean.pkl'
    
train: 
  batch_size: 32
  # accum_grad: 8
  num_workers: 8
  loss_fn: 
    name: 'ce_caption_loss'
  optimizer: 
    name: 'AdamW'

