experiment_name: 'amino_acid_stage1_unimodal_text_reconstruction_train'

lightning:
  trainer:
    gpus: 1
    max_epochs: 40
    lr: 5e-6
    precision: 16
    auto_lr_find: false
    num_sanity_val_steps: 0
    check_val_every_n_epochs: 1 # can change
  checkpoint_callback:
    monitor: 'val/ROUGE_L'
    dirpath: '/pasteur/u/esui/data/c3/clasp_ckpt'
    save_last: true
    mode: 'max'
    save_top_k: 2
  logger:
    logger_type: 'WandbLogger'
    save_dir: '/pasteur/u/esui/data/logger/'
    name: 'clip_prefix_cap_extra_datasets'
    project: 'clip_prefix_cap_coco'

encoder:
    modality: 'language' # 'language', 'both'
    embed_dim: 768

decoder:
    # Decode to language
    modality: 'language'
    model: 'gpt2'


model: 
  num_layers: 8
  mapping_type: 'mlp'
  prefix_length: 10
  clip_size: 10
  normalize_prefix: False
  is_rn: False
  gpt2_type: 'gpt2'

data: 
  dataset: 'amino_acid'
  seed: 1234
  train_split: 'train'
  train_data_path: '/pasteur/u/esui/data/c3/data_clasp_train.pkl'
  val_data_path: '/pasteur/u/esui/data/c3/data_clasp_val.pkl'
  test_data_path: '/pasteur/u/esui/data/c3/data_clasp_test.pkl'
  out_dir: '/pasteur/u/esui/data/c3/clip_prefix_clasp_ckpts'
    
train: 
  batch_size: 20
  accumulate_grad_batches: 2
  num_workers: 8
  loss_fn: 
    name: 'ce_caption_loss'
  optimizer: 
    name: 'AdamW'
  scheduler:
    name: 'linear_schedule_with_warmup'
    warmup_steps: 25

